import torch
from .word_list import WordList
from .bigram_encoder import BigramEncoder
from .utils import global_generator, prepare_data

type BigramPair = tuple[tuple[str], str]

class SimpleBigram:
    """ Very basic bigram model based generated by counting bigrams in the
    specified input set.
    """

    def __init__(self, word_list: WordList, encoder: BigramEncoder):
        """ Initializes the model with a matrix of probabilities generated by
        counting bigrams in the input set.

        :param word_list: A WordList object containing the words to be used to
        compute bigram probabilities.
        :param encoder: A BigramEncoder object used to index-encode the
        characters in the word list.
        """

        assert isinstance(word_list, WordList), "Invalid word_list (arg #1)"
        assert isinstance(encoder, BigramEncoder), "Invalid encoder (arg #2)"

        self._bigram_counts = torch.zeros(
            (word_list.vocabulary_size, word_list.vocabulary_size),
            dtype=torch.float)
        self._bigram_probs = torch.zeros(
            (word_list.vocabulary_size, word_list.vocabulary_size),
            dtype=torch.float)

        for word in word_list:
            for pair in word.get_pairs(1):
                row, col = self._get_pair_indices(pair, encoder)
                self._bigram_counts[row, col] += 1

        sums = self._bigram_counts.sum(1, keepdim=True)
        self._bigram_probs = self._bigram_counts / sums

    def _get_pair_indices(self, pair, encoder):
        row = encoder.get_index(pair[0][0])
        col = encoder.get_index(pair[1][0])
        return row, col

    def _show_data(data, encoder):
        row_size, col_size, *_ = data.shape
        for row_index in range(row_size):
            row = data[row_index]
            first = encoder.get_char(row_index)
            labels = []
            probs = []
            for col_index in range(col_size):
                second = encoder.get_char(col_index)
                labels.append(f'{first+second:^8}')
                probs.append(data[row_index, col_index].item())
            print(' '.join(labels))
            print(' '.join([f'{prob:^8.4f}' for prob in probs]))

    def __repr__(self) -> str:
        """ Representation of the model. """
        return f'SimpleBigram({self._bigram_counts.shape})'

    def __call__(
        self,
        inputs: int | float | torch.Tensor,
        labels: torch.Tensor = None,
        generator: torch.Generator = None
    ) -> tuple[torch.Tensor, torch.Tensor | None]:
        """ Evaluates the model on the given inputs and provides a probability
        of the expected outcome.

        If labels are provided, loss is calculated using average negative log
        loss.

        :param inputs: Inputs to the model, specified as a number or a tensor of
        numbers.
        :param labels: Labels to use for loss calculation. If None, no loss is
        returned
        :param generator: A generator object used to make a selection based on a
        bigram's probabilities.
        """

        if generator is None:
            generator = global_generator

        if isinstance(inputs, (int, float)):
            inputs = torch.tensor([inputs], dtype=torch.float)
        assert isinstance(inputs, torch.Tensor), 'Invalid inputs (arg #1)'

        indices = inputs.int()
        predictions = torch.multinomial(self._bigram_probs[indices],
                                        1,
                                        replacement=True,
                                        generator=generator)
        loss = None
        if labels is not None:
            loss = -torch.log(self._bigram_probs[indices, labels]).mean()

        return predictions, loss

    def generate_word(self,
                      encoder: BigramEncoder,
                      generator: torch.Generator = None):
        """ Generates a word using the model.

        :param encoder: The encoder used to convert indices to characters.
        :param generator: A torch generator object used to randomly select the
        next character based on model outputs.

        :return: The generated word as a string.
        """

        if generator is None:
            generator = global_generator

        chars = []
        index = encoder.get_index('.')
        while True:
            index, _ = self(index, None, generator)
            index = index.item()
            if index == encoder.get_index('.'):
                break
            chars.append(encoder.get_char(index))
        return ''.join(chars)

    def get_count(self, pair: BigramPair, encoder: BigramEncoder) -> int:
        """ Returns the count of a specific bigram pair.

        :param pair: A tuple representing the bigram pair.
        :param encoder: The encoder used to convert characters to indices.
        :return: The number of times that the bigram pair appeared in the data
        set.
        """

        row, col = self._get_pair_indices(pair, encoder)
        return self._bigram_counts[row, col].item()

    def get_probability(self, pair: BigramPair, encoder: BigramEncoder) -> float:
        """ Returns the probability of occurence a specific bigram pair.

        :param pair: A tuple representing the bigram pair.
        :param encoder: The encoder used to convert characters to indices.
        :return: The probability of the bigram pair appearing in the data
        set.
        """

        row, col = self._get_pair_indices(pair, encoder)
        return self._bigram_probs[row, col].item()

    def get_log_likelihood(self, pair: BigramPair, encoder: BigramEncoder) -> float:
        """ Returns the negative log likelihood of a specific bigram pair.

        :param pair: A tuple representing the bigram pair.
        :param encoder: The encoder used to convert characters to indices.
        :return: The negative log likelihood of the bigram pair appearing in the
        data set.
        """

        row, col = self._get_pair_indices(pair, encoder)
        return -torch.log(self._bigram_probs[row, col])

    def show_counts(self, encoder: BigramEncoder):
        """ Displays the bigram counts in a formatted matrix.

        :param encoder: The encoder used to convert characters to indices.
        """

        SimpleBigram._show_data(self._bigram_counts, encoder)

    def show_probs(self, encoder: BigramEncoder):
        """ Displays the bigram probabilities in a formatted matrix.

        :param encoder: The encoder used to convert characters to indices.
        """

        SimpleBigram._show_data(self._bigram_probs, encoder)

    def prepare_data(self, words: WordList, encoder) -> tuple[torch.Tensor, torch.Tensor]:
        """ Prepares data that can be used to train this model.

        :param words: A WordList object containing the words to be used to
        generate the dataset.
        :param encoder: The encoder used to convert characters to indices.
        :return: A tuple containing the input and label tensors.
        """

        transform = lambda chars: torch.tensor(
            [encoder.get_index(char[0]) for char in chars])
        return prepare_data(words[:], transform)
